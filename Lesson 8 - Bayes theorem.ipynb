{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Sean Tulin\n",
    "<br>\n",
    "Date: Feb. 16, 2022\n",
    "<br>\n",
    "PHYS 2030 W22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#46769B>Lesson 8: Bayes theorem</font>\n",
    "\n",
    "## <font color=#46769B>Introduction</font>\n",
    "\n",
    "Monte Carlo sampling is closely related to the topic of __Bayesian analysis__ (also known as Bayesian inference or Bayesian statistics). Bayesian analysis is a framework for making probabilistic statements about how likely something is given the data at hand. We have some familiarity with this from Exercises 11, 12, and 15 where we fit galactic observations to infer the total mass. \n",
    "\n",
    "Bayesian analysis relies on a mathematical result known as __Bayes theorem__. Let's illustrate this theorem with a simple example.\n",
    "\n",
    "Suppose you have a medical test and you test positive for a disease. The error rate of the test is only 1\\%. What is the probability that you have the disease? You might be tempted to answer 99\\%. However, this is not the case.\n",
    "\n",
    "The key concept of Bayes theorem is that we need to include our *prior knowledge* when calculating a probability. For example, suppose we know that 0.1\\% of the population has this disease. This is an example of a __prior__.\n",
    "\n",
    "Let's see how this changes our answer. Suppose we have 100,000 people in our population, which means that 100 people have the disease and 99,900 do not.\n",
    "Now, everyone gets tested: \n",
    "- Since the test is 99\\% accurate, 99 out of the 100 people with the disease will test positive.\n",
    "- Since 1\\% of tests will give the wrong result, 999 out of 99,900 people without the disease will also test positive.\n",
    "\n",
    "So, if you are a random person in the population that tests positive, you are ten times more likely to be a false positive than someone who actually has the disease. The probability that you have the disease if you test positive is only\n",
    "$$\\frac{\\mathrm{number\\; who \\;test \\;positive\\; with \\;the \\;disease}}{\\rm total\\; number \\;who \\;test\\; positive}\n",
    "= \\frac{99}{99+999} \\approx 9\\%\\, .$$\n",
    "\n",
    "What was the flaw in our original thinking? We implicitly assumed that having-the-disease and not-having-the-disease were *equally* likely. Let's go through the same argument again, assuming a prior that 50\\% of the population has the disease (e.g., Omicron). \n",
    "Out of a population of 100,000, there are 50,000 people with the disease. If everyone gets tested:\n",
    "- 49,500 out of 50,000 people with the disease will test positive (99\\%)\n",
    "- 500 people of 50,000 people without the disease will test positive (1\\%)\n",
    "\n",
    "Now the probability that you have the disease if you test positive is\n",
    "$$\\frac{\\mathrm{number\\; who \\;test \\;positive\\; with \\;the \\;disease}}{\\rm total\\; number \\;who \\;test\\; positive}\n",
    "= \\frac{49,500}{49,500+500} = 99\\%\\, ,$$\n",
    "as you originally might have thought.\n",
    "\n",
    "The lesson from this is:\n",
    "- Priors matter. \n",
    "- Anytime you calculate probability, you are *always* including a prior whether you specify it or not. \n",
    "- If you don't specify your prior, you are assuming that each possibility is equally likely, which may not be what you want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#46769B>Conditional probability</font>\n",
    "\n",
    "Before we write down Bayes theorem, we need to introduce the notion of __conditional probabilities__. Suppose we have two events, $A$ and $B$. The conditional probability $P(A|B)$ is the probability that $A$ occurs *given that* $B$ occurs.<font color=red>$^1$</font> Likewise, the conditional probability $P(B|A)$ is the probability that $B$ occurs, given that $A$ occurs. It is not the case that $P(A|B) = P(B|A)$.\n",
    "\n",
    "In our previous example:\n",
    "- $A$ is having the disease.\n",
    "- $B$ is testing positive for the disease.\n",
    "\n",
    "Now,\n",
    "- $P(A|B)$ is the probability of you having the disease given that you tested positive. According to our first calculation, this is $\\approx 9\\%$.\n",
    "- $P(B|A)$ is the probability of you testing positive given that you have the disease. This is simply $99\\%$, since the error rate is $1\\%$.\n",
    "\n",
    "### <font color=#46769B>Footnotes:</font>\n",
    "<font color=red>$^1$</font> The standard notation here is unfortunately very confusing. We previously discussed *transition* probabilities $Q(x|x^\\prime)$. Here we are discussing *conditional probabilities* $P(A|B)$. While they are similar notationally, they are distinct concepts.\n",
    "- For the transition probability $Q(x|x^\\prime)$, $x$ and $x^\\prime$ are different outcomes (samples) of the *same* quantity. \n",
    "- For the conditional probability $P(A|B)$, $A$ and $B$ relate to outcomes of *different* quantities. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#46769B>Bayes theorem</font>\n",
    "\n",
    "Bayes theorem allows us to relate $P(A|B)$ and $P(B|A)$ according to the following formula:\n",
    "$$ P(A|B) = \\frac{P(B|A) P(A)}{P(B)} \\, . \\qquad (1)$$\n",
    "Here $P(A)$ and $P(B)$ are the total probabilities of $A$ or $B$, respectively.\n",
    "- $P(A)$ is the total probability of having the disease. It is the *prior probability* that we assumed, $P(A) = 0.1\\%$. Out of 100,000 people, there are 100 with the disease.\n",
    "- $P(B)$ is the total probability of testing positive. We can write it as:\n",
    "$$P(B) = P(B|A)P(A) + P(B|{\\rm not} \\; A) P({\\rm not} \\; A)$$\n",
    "Note that \"${\\rm not}\\; A$\" means *not* having the disease. $P(B)$ is the *marginal* probability since we are marginalizing (averaging) over the different possibilities of whether you have the disease or not, only caring about whether you test positive. For the example above, we can calculate $P(B)$ as follows:\n",
    "$$P(B) = \\underbrace{99\\%}_{P(B|A)} \\times \\underbrace{0.1 \\%}_{P(A)} + \\underbrace{1\\%}_{P(B|{\\rm not} \\: A)} \\times \\underbrace{99.9\\%}_{P({\\rm not}\\: A)} = 1.098\\%\\,.$$\n",
    "Out of 100,000 people, there are 99 people with the disease who test positive and 999 people without the disease who test positive, for a total of 1098 people who test positive.\n",
    "\n",
    "We can check Bayes theorem for our example. The right side of (1) gives \n",
    "$$\\frac{P(B|A)P(A)}{P(B)} = \\frac{99\\% \\times 0.1\\%}{1.098\\%} \\approx 9\\% \\, ,$$\n",
    "which is the same result we found for $P(A|B)$.\n",
    "$P(A|B)$ is known as the __posterior probability__, that is, the probability of $A$ given all your knowledge (including the prior on $A$ and the condition that $B$ is satisfied).\n",
    "\n",
    "### <font color=#46769B>Proof of Bayes theorem</font>\n",
    "\n",
    "Let $P(A \\cap B)$ denote the probability of *both* $A$ and $B$ (for example, testing positive *and* having the disease). We can calculate this probability in two ways:\n",
    "$$P(A \\cap B) = P(A|B) P(B) = P(B|A) P(B) \\, . \\qquad (2)$$\n",
    "Diving both sides by $P(B)$ yields (1). \n",
    "\n",
    "For the example above:\n",
    "- $P(A|B) P(B)$ says $P(B)\\approx 1\\%$ of the population will test positive. Among those, $P(A|B)\\approx 9\\%$ will have the disease.\n",
    "- $P(B|A) P(A)$ says $P(A) = 0.1\\%$ of the population will have the disease. Among these, $P(B|A) = 99\\%$ will test positive.\n",
    "\n",
    "In either case, the fraction of people that who both test postive *and* have the disease is the same no matter how we define things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#46769B>Example: Coin flip</font>\n",
    "\n",
    "Suppose you have a coin with an unknown probability $p$ of getting heads (and probability $1-p$ of getting tails). You flip the coin 10 times in a row and get 10 heads. What is the probability that it is a fair coin?\n",
    "\n",
    "It might be tempting to say that you definitely do *not* have a fair coin, but in fact the question so far is ill-defined. You need more information: What types of coins are there? How prevalent are different types of coins? In other words, you need to know the *priors*.\n",
    "\n",
    "Let's suppose that one of out of every 1000 coins is a trick coin that will always yield heads. Let's use Bayes theorem to answer the question:\n",
    "- $A$ is having a fair coin. (\"${\\rm not}\\: A$\" is having a biased coin that always yields heads.)\n",
    "- $B$ is getting heads 10 times in a row.\n",
    "\n",
    "We want to calculate $P(A|B)$, the probability of having a fair coin given that we got heads ten times in a row.\n",
    "We have the following:\n",
    "- The probability of having a fair coin is $P(A) = 99.9\\%$. The probability of having a biased coin is $P({\\rm not} \\: A) = 0.1\\%$\n",
    "- The probability of getting heads ten in a row given a fair coin is $P(B|A) = \\left(\\frac{1}{2} \\right)^{10} = \\frac{1}{1024}$. The probability of getting heads ten times in a row with a biased coin is $P(B|{\\rm not} \\; A) = 100\\%$.\n",
    "- The probability of getting heads ten times in a row, *marginalized* over whether or not we had a fair coin, is\n",
    "$$P(B) = \\underbrace{99.9\\%}_{\\rm P(A)} \\times \\underbrace{\\frac{1}{1024}}_{P(B|A)} + \\underbrace{0.1\\%}_{P({\\rm not}\\, A)} \\times \\underbrace{100\\%}_{P(B|{\\rm not}\\, A)} \\approx 0.2\\%\\, .$$\n",
    "\n",
    "So, according to Bayes theorem, the posterior probability of a fair coin is \n",
    "$$P(A|B) = \\frac{P(B|A) P(A)}{P(B)} \\approx 49\\% \\, .$$\n",
    "\n",
    "The code below calculates this number. It may be counterintuitive! The likelihood of getting 10 heads with a fair coin is low, but so is the probability of having anything other than a fair coin to begin with.\n",
    "\n",
    "Play around with the code below. \n",
    "- You can change the number of flips in a row that all land on heads. Suppose you get 20 heads in a row, does this change the odds of having a fair coin?\n",
    "- You can change the probability of having a biased coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of a fair coin: 0.000951813829407141\n",
      "probability of a biased coin: 0.9990481861705929\n"
     ]
    }
   ],
   "source": [
    "num_flips = 10\n",
    "probability_of_biased_coin = 0.001\n",
    "\n",
    "P_A = 1 - probability_of_biased_coin\n",
    "P_notA = probability_of_biased_coin\n",
    "\n",
    "P_B_given_A = (1/2)**num_flips\n",
    "P_B_given_notA = 1\n",
    "\n",
    "P_B = P_B_given_A*P_A + P_B_given_notA*P_notA\n",
    "\n",
    "print(\"probability of a fair coin:\", P_B_given_A*P_A/P_B)\n",
    "print(\"probability of a biased coin:\", P_B_given_notA*P_notA/P_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#46769B>Bayesian statistics</font>\n",
    "\n",
    "If you understand this comic, you understand Bayes theorem. \n",
    "\n",
    "<div>\n",
    "<img src=\"https://imgs.xkcd.com/comics/frequentists_vs_bayesians.png\" width=\"400\">\n",
    "<i>Figure credit: xkcd.com</i>\n",
    "</div>\n",
    "\n",
    "In case this is mysterious to you, let's define:\n",
    "- $A$ is the sun exploding. \"${\\rm not} \\; A$\" is the sun not exploding. \n",
    "- $B$ is machine *telling* us the sun exploded.\n",
    "\n",
    "The statistician on the left argues:\n",
    "- The probability for the machine to lie and tell us that the sun exploded when it did *not* is $1/36 \\approx 3\\%$.\n",
    "- Therefore, there is a $1/36 \\approx 3\\%$ chance that the sun did *not* explode given that machine told us it did.\n",
    "- Hence, the probability that sun *did* explode (given that the machine told us it did) is $35/36 \\approx 97\\%$.\n",
    "\n",
    "According to Bayes theorem, where is the flaw in this logic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#46769B>Bayes theorem with continuous variables</font>\n",
    "\n",
    "So far, we considered Bayes theorem for a situation with discrete options for $A$. For example:\n",
    "- $A$ was either having the disease or not.\n",
    "- $A$ was either having a fair coin or not.\n",
    "\n",
    "Now consider a situation in which $A$ is represented by a continuous variable.\n",
    "We want to calculate the *posterior probability distribution function* $P(A|B)$ for our continuous variable $A$, given that $B$ has occurred.\n",
    "\n",
    "Bayes theorem still says\n",
    "$$P(A|B) = \\frac{P(B|A) P(A)}{P(B)} \\, .$$\n",
    "The main difference is now is how we calculate the marginalized probability $P(B)$. Previously, we summed over the two different options:\n",
    "$$P(B) = P(B|A) \\, P(A) + P(B|{\\rm not} \\, A) \\, P({\\rm not} \\, A)$$\n",
    "Now we must integrate over all possible values $A$ can take:\n",
    "$$P(B) = \\int dA \\, P(B|A) \\, P(A) \\, .$$\n",
    "\n",
    "Let's go through an example to see how this works.\n",
    "\n",
    "## <font color=#46769B>Example: Coin flip (continued)</font>\n",
    "\n",
    "\n",
    "Say we have a coin with an unknown probability $p$ for getting heads. We flip the coin and get heads $n$ times in a row. What can we say about $p$?\n",
    "\n",
    "First we need a prior for $p$. In the example above, we assumed a discrete choice that $p=0.5$ ($99.9\\%$ of the time) or $p=1$ ($0.1\\%$ of the time). Here we will allow $p$ to be a continuous variable between $[0,1]$. We will assume a *uniform* prior for $p$, which just means that all values of $p$ are equally likely. We write this prior as\n",
    "$$P(p) = \\left\\{ \\begin{array}{cc} 1 & 0 \\le p \\le 1 \\\\ 0 & {\\rm otherwise} \\end{array} \\right. \\, .$$\n",
    "\n",
    "\n",
    "The different events in Bayes theorem are:\n",
    "- $A$ is \"having a coin that has probability $p$ of getting heads\"\n",
    "- $B$ is \"getting heads $n$ times in a row\"\n",
    "\n",
    "We will change the notation a bit to make it more clear what $A$ and $B$ are:\n",
    "- $P(A|B) = P(p|n \\; {\\rm heads})$ is the *conditional* probability distribution function for $p$, given that we obtained $n$ heads in a row. Note that $P(p|n \\; {\\rm heads})$ is a PDF for the continuous variable $p$. This is the posterior distribution we want to compute.\n",
    "- $P(B|A) = P(n \\; {\\rm heads}|p)$ is the *conditional* probability for getting heads $n$ times, given that the coin had probability $p$ to get heads each time. This is simply\n",
    "$$P(n \\; {\\rm heads}|p) = p^n \\, .$$\n",
    "- $P(A) = P(p)$ is the prior on having a coin with probability $p$, given above.\n",
    "- $P(B) = P(n \\; {\\rm heads})$ is the *marginalized* probability to get $n$ heads in a row given at all probabilities $p$ are equally likely. We can calculate this:\n",
    "$$P(n \\; {\\rm heads}) = \\int dp \\, P(n \\; {\\rm heads}|p)\\,  P(p) = \\int_0^1 dp \\, p^n = \\frac{1}{n+1} \\, .$$\n",
    "\n",
    "Using Bayes theorem, we can calculate the *posterior PDF* for having a coin with probability $p$:\n",
    "$$P(p|n \\; {\\rm heads}) = \\frac{P(n \\; {\\rm heads}|p) \\, P(p)}{P(n \\; {\\rm heads})} \n",
    "= \\left\\{ \\begin{array}{cc} (n+1) p^n & 0 \\le p \\le 1 \\\\ 0 & {\\rm otherwise} \\end{array} \\right. \\, .$$\n",
    "\n",
    "We were able to calculate the posterior for $p$ analytically. \n",
    "\n",
    "Now let's write a short code to verify that this works out. Here is the logic of the code to follow:\n",
    "- Select $N = 10^6$ random coins, each with their own value of $p$ (sampled uniformly between $[0,1]$).\n",
    "- Flip each coin $n=3$ times. \"Flipping a coin $n$ times\" means selecting that coin with probability $p^n$. That is, we choose a random number $r$ within $[0,1]$. If $r < p^n$, then we have gotten heads $n$ times in a row.\n",
    "- Create a list `landed_on_heads_n_times` that keeps track of whether a given coin $i$ landed on heads $n$ times or not. \n",
    "    - If coin $i$ landed on heads $n$ times, then assign `landed_on_heads_n_times[i] = 1` for that coin.\n",
    "    - Otherwise, set `landed_on_heads_n_times[i] = 0` for that coin.\n",
    "- Make a histogram for the values of $p$ only for those coins that landed on heads $n$ times. This will be done using `plt.hist(p,weights=landed_on_heads_n_times)`, that is, assigning a weight of `1` for coins that landed on heads $n$ times and a weight of `0` for coins that do not.\n",
    "- Compare to the analytic result for $P(p|n \\; {\\rm heads})$ derived above.\n",
    "\n",
    "Now to the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Number of coins\n",
    "num = 10**6\n",
    "\n",
    "# Number of flips per coin\n",
    "n = 3\n",
    "\n",
    "# Sample p values for each coin\n",
    "p = np.random.rand(num)\n",
    "\n",
    "# Random number to decide whether landed on heads n times\n",
    "r = np.random.rand(num)\n",
    "\n",
    "# Keep track of whether a coin landed on heads n times\n",
    "landed_on_heads_n_times = np.where( r < p**n, 1, 0 )\n",
    "\n",
    "# Make a histogram of the posterior PDF for p\n",
    "plt.hist(p,weights=landed_on_heads_n_times,density=True,bins=30,label=\"Sampling\")\n",
    "\n",
    "# Compare to analytic result above\n",
    "x = np.linspace(0,1)\n",
    "y = (n+1)*x**n\n",
    "plt.plot(x,y,label=\"P(p|n heads)\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('p')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
