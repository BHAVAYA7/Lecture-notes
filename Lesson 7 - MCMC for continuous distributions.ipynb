{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Sean Tulin\n",
    "<br>\n",
    "Date: Feb. 9, 2022\n",
    "<br>\n",
    "PHYS 2030 W22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#46769B>Lesson 7: Markov Chain Monte Carlo for continuous distributions</font>\n",
    "\n",
    "## <font color=#46769B>Motivation</font>\n",
    "\n",
    "Let us generalize our discussion from Lesson 6 to the case of probability distribution functions of continuous variables. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#46769B>Metropolis algorithm for continuous distributions</font>\n",
    "\n",
    "Suppose we have a target PDF $P(x)$, where $x$ is a continuous variable that we want to sample. To be concrete, let's consider an exponential function\n",
    "$$P(x) = \\left\\{ \\begin{array}{cc} a e^{-ax} & x > 0 \\\\ 0 & {\\rm otherwise} \\end{array} \\right. \\, .$$ \n",
    "For future reference, we recall that the true mean and standard deviation of this distribution are $\\mu = \\sigma = 1/a$.\n",
    "\n",
    "The general procedure for performing an MCMC simulation is generally the same as for a discrete variable. \n",
    "\n",
    "### <font color=#46769B>Choosing your proposal distribution</font>\n",
    "\n",
    "First, we need to decide on a proposal (transition) PDF $Q(x|x^\\prime)$. In the Metropolis algorithm, the proposal distribution is assumed to be symmetric, i.e.,\n",
    "$$Q(x|x^\\prime) = Q(x^\\prime|x) \\, .$$\n",
    "In this course, we will always choose a __normal distribution__ for our proposal distribution: \n",
    "$$Q(x|x^\\prime) = \\frac{1}{\\sqrt{2\\pi \\sigma_q^2}} \\, e^{-\\frac{(x-x^\\prime)^2}{2 \\sigma_q^2}} \\, .$$\n",
    "That is, you draw the *new* sample $x$ from a normal distribution centered at the *old* sample $x^\\prime$. \n",
    "This choice for $Q(x|x^\\prime)$ is the most common one for MCMC simulations, in part because it is clearly symmetric (it is invariant under $x \\leftrightarrow x^\\prime$).\n",
    "\n",
    "We still have a choice to make: we are free to choose any value for the width of our proposal distribution, $\\sigma_q$. (We label it $\\sigma_q$ to make it clear that it is related to the proposal PDF $Q$ and not to be confused with the true $\\sigma$ from our target PDF $P$.)\n",
    "\n",
    "There is always a \"sweet spot\" where $\\sigma_q$ is neither too large nor too small, where your simulation will be optimized.\n",
    "We will gain some experience in how to optimize $\\sigma_q$ below.\n",
    "\n",
    "Let's summarize the main idea of how to choose the best $\\sigma_q$. The main goal of our MCMC simulation is to obtain a list of $x$ samples\n",
    "$$(x_0, \\, x_1, \\, x_2, \\, ... , \\, x_{N-1})$$\n",
    "that are scattered diversely throughout the region of maximum probability. Consider the figure below. The darker shaded region represents the region of higher probability and the green point represents $x^\\prime$. (For visual clarity, the picture represents sampling two variables in a plane, say, $x$ and $y$.)\n",
    "\n",
    "<div>\n",
    "<img src=\"https://github.com/PHYS-2030-Computational-Methods/Lecture-notes/raw/main/figures/MCMC_step_size.png\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "- If $\\sigma_q$ is large, we are more likely to make larger steps in $x$. After a large step, $x$ will be far outside the most probable region. Such new points are unlikely to be accepted, and we end up with the same point $x^\\prime$ repeated in our chain.\n",
    "\n",
    "- If $\\sigma_q$ is small, we are more likely to make smaller steps in $x$. Since each new step $x$ is near the old point $x^\\prime$, the acceptance ratio is close to one and new points are likely to be accepted. However, we end up with many points that are closely correlated with each other.\n",
    "\n",
    "- If $\\sigma_q$ is just right, the step size will be comparable to the size of the region we want to sample from. We will have a mix of accepted and rejected samples.\n",
    "\n",
    "In practice, it is important to __tune__ your MCMC to determine the best value of $\\sigma_q$. This is similar to the iterative tuning we did for importance sampling.\n",
    "\n",
    "\n",
    "### <font color=#46769B>Acceptance/rejection</font>\n",
    "\n",
    "The process for accepting or rejecting a new sample is the same as we discussed for a discrete distribution. Here we recap the steps:\n",
    "- Given a previous sample $x^\\prime = x_{i-1}$, generate a new sample $x$ by sampling from $Q(x|x_{i-1})$.\n",
    "- Calculate the acceptance ratio $\\mathcal{A} = P(x)/P(x_{i-1})$.\n",
    "    - If $\\mathcal{A} > 1$, we *always* accept the new point.\n",
    "    - If $\\mathcal{A} < 1$, we *either* accept or reject the new point. We decide to accept or reject randomly: we accept with probability $\\mathcal{A}$ (and therefore we reject with probability $1-\\mathcal{A}$).\n",
    "- The next value in the chain, $x_i$, depends on whether we accept or reject:\n",
    "    - If we accept $x$, we set $x_i = x$, i.e., saving our new sample to the chain.\n",
    "    - If we reject $x$, we set $x_i = x_{i-1}$, i.e., *repeating our previous value in the chain*. \n",
    "\n",
    "There is a __remarkable thing__ about MCMC algorithms that is worthwhile to notice. The target PDF $P(x)$ only enters in the acceptance ratio $A = P(x)/P(x^\\prime)$. Because $\\mathcal{A}$ is the *ratio* of the probabilities at two different points, the *normalization* of $P(x)$ is actually irrelevant. In practice, especially for multivariate sampling problems, finding the normalization is either challenging or impractical. For MCMC algorithms, we do not need to normalize our target PDF.\n",
    "\n",
    "### <font color=#46769B>Summary</font>\n",
    "\n",
    "Let's summarize how we implement the Metropolis algorithm for sampling from our exponential PDF $P(x)$, with $a=1$.\n",
    "\n",
    "Before we begin, we need to choose:\n",
    "- An initial value for the chain, $x_0$. Let's choose $x_0 = 1$.\n",
    "- The transition PDFs $Q(x|x^\\prime)$. Let's choose a normal distribution with $\\sigma_q=1$.\n",
    "- The number of samples $N$ we want in our chain. Let's try $N=10^5$.\n",
    "\n",
    "Next, we do a `for` loop over an index `i` that will generate $N$ entries in our chain. For each iteration in the `for` loop:\n",
    "- Given $x_{i-1}$, generate a new sample $x$ from $Q(x|x_{i-1})$. Recall, this means we are sampling from a normal distribution centered at mean $x_{i-1}$ with width $\\sigma_q$ to get $x$. The line of code that does this is\n",
    "```py\n",
    "x = np.random.normal(x_old,sigma)\n",
    "```\n",
    "where `x_new` is our new sample $x$ and `x_old` is $x_{i-1}$. Note that there is no `num` appearing here. We are only getting the next *one* sample in the chain.\n",
    "- Calculate the acceptance ratio $\\mathcal{A} = P(x)/P(x_{i-1})$.\n",
    "- Acceptance/rejection step:\n",
    "    - If accept, set $x_i = x$. \n",
    "    - Else (reject), set $x_i = x_{i-1}$, i.e., repeat the previous value.\n",
    "\n",
    "After $N-1$ iterations, the `for` loop terminates (we started with one sample $x_0$ to begin with). Our chain consists of $N$ samples for $x$:\n",
    "$$x = \\left( x_0, \\, x_1, \\, x_2, \\, ... , \\, x_{N-1}\\right) \\, .$$\n",
    "Now, we can calculate anything we like as if we had sampled from $P(x)$ directly. For example, the mean value of $x$ is\n",
    "$$\\langle x \\rangle = \\frac{1}{N} \\sum_{i=0}^{N-1} x_i \\, .$$\n",
    "The mean value of any function of $x$ is\n",
    "$$\\langle f(x) \\rangle = \\frac{1}{N} \\sum_{i=0}^{N-1} f(x_i) \\, .$$\n",
    "Unlike importance sampling, we do not need to include any weights in our calculations.\n",
    "\n",
    "Here is some code that implements all this. We will also calculate the mean and standard deviation. Recall that the true mean and standard deviations are equal to $\\mu = a$ and $\\sigma=a$, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num = 10**5\n",
    "a = 1\n",
    "x0 = 1\n",
    "sigma = 1\n",
    "\n",
    "# Define P(x)\n",
    "def P(x):\n",
    "    return np.where( x >= 0, a*np.exp(-a*x), 0 )\n",
    "    \n",
    "# Initialize the first value in the chain [x0]\n",
    "x_samples = [x0]\n",
    "\n",
    "for i in range(num-1):\n",
    "    \n",
    "    # Previous value of x\n",
    "    x_old = x_samples[i]\n",
    "    \n",
    "    # Sample new value of x\n",
    "    x_new = np.random.normal(x_old,sigma)\n",
    "    \n",
    "    # Acceptance ratio\n",
    "    A = P(x_new)/P(x_old)\n",
    "    \n",
    "    # Check whether accept or reject\n",
    "    \n",
    "    # Accept always\n",
    "    if A > 1:\n",
    "        x_samples.append(x_new)\n",
    "    \n",
    "    # Accept with probability A\n",
    "    else:\n",
    "        # Randomly decide to accept\n",
    "        r = np.random.rand()\n",
    "        if r < A:\n",
    "            x_samples.append(x_new)\n",
    "        else:\n",
    "            x_samples.append(x_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a histogram of our sample\n",
    "plt.hist(x_samples,bins=30,density=True,label='MCMC')\n",
    "\n",
    "# Compare to our PDF\n",
    "x = np.linspace(0,8)\n",
    "plt.plot(x,P(x),label='P(x)')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b48e3be708>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_samples[:5000],'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#46769B>Markov Chain Monte Carlo</font>\n",
    "\n",
    "MCMC is a different algorithm for sampling $x$ from a probability distribution $P(x)$. Before we discuss the algorithm, let's highlight the main differences with importance sampling.\n",
    "- MCMC involves a proposal distribution $Q$ that you are free to choose. Unlike importance sampling, $Q$ *depends* on the previous sample. We write this as: $$Q(x|x^\\prime)$$\n",
    "This the probability to sample $x$ *given* that the previous sample was $x^\\prime$. $Q(x|x^\\prime)$ is known as a __transition probability__.\n",
    "- MCMC generates samples for $x$ that are drawn from the *target* distribution $P(x)$ directly. *No weights are needed.* Importance sampling draws samples for $x$ from the *proposal* distribution and we needed to include weights to calculate quantities with respect to $P(x)$. \n",
    "- In MCMC, after drawing each sample $x_i$, there is an additional step where you must decide whether or not to accept the sample. This is known as the __acceptance/rejection step__.\n",
    "\n",
    "The list of samples for $x$ is called a __chain__. Since each new sample depends on the one before, MCMC is an iterative process where you build your chain one sample at a time until it has the desired length $N$.\n",
    "\n",
    "Now we will go through in detail how (and why!) MCMC works for the coin flip example.\n",
    "\n",
    "### <font color=#46769B>Transition probabilities</font>\n",
    "\n",
    "The first step is to choose your transition probabilities $Q(x|x^\\prime)$. For flipping a coin, the only choice is a Bernoulli distribution, but it will depend on whether the previous sample $x^\\prime$ was heads or tails.\n",
    "\n",
    "Suppose our previous sample is tails ($x^\\prime = 0$). Then we say the probability of getting heads or tails for the next sample $x$ is\n",
    "$$Q(x|0) = \\left\\{ \\begin{array}{cl} q & x=1  \\\\ 1-q & x=0 \\end{array} \\right. \\, .$$\n",
    "Now suppose our previous sample is heads ($x^\\prime = 1$). Then we say the probability of getting heads or tails for the next sample $x$ is\n",
    "$$Q(x|1) = \\left\\{ \\begin{array}{cl} \\bar{q} & x=1  \\\\ 1-\\bar{q} & x=0 \\end{array} \\right. \\, .$$\n",
    "That is, $Q(x|0)$ and $Q(x|1)$ are different distributions. \n",
    "Of course, the total probability for *either* $x=1$ or $x=0$ is always unity, so we must have\n",
    "$$Q(1|0) + Q(0|0) = q + (1-q) = 1 \\, , \\qquad  Q(1|1) + Q(0|1) = \\bar{q} + (1-\\bar{q}) = 1 \\, .$$\n",
    "However, $q$ and $\\bar{q}$ are different in general and we are free to choose them as we like.\n",
    "\n",
    "We can make a map to illustrate all the different possible transitions and their probabilities:\n",
    "<div>\n",
    "<img src=\"https://github.com/PHYS-2030-Computational-Methods/Lecture-notes/raw/main/figures/MCMC_coin_flip.png\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "\n",
    "The most common (and original) type of MCMC is known as the __Metropolis algorithm__. This is the main algorithm we will use in this course. In the Metropolis algorithm, we make an assumption that the transition probability is *symmetric*,\n",
    "$$Q(x|x^\\prime) = Q(x^\\prime|x) \\, ,$$\n",
    "so the probablity of sampling $x^\\prime \\to x$ is the same as sampling $x \\to x^\\prime$.\n",
    "For the coin flip, the Metropolis algorithm assumes $Q(0|1) = Q(1|0)$, i.e., taking a special choice that $\\bar{q} = 1-q$.\n",
    "\n",
    "The more general MCMC setup where $Q(x|x^\\prime) \\ne Q(x^\\prime|x)$ is known as the __Metropolis-Hastings algorithm__.\n",
    "For the coin flip, Metropolis-Hastings simply allows $q$, $\\bar{q}$ to be independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#46769B>Acceptance/rejection</font>\n",
    "\n",
    "It is an important step in MCMC algorithms to decide whether to accept or reject a new sample. The process is:\n",
    "- Given a previous sample $x_{i-1}$, generate a new sample $x$ by sampling from $Q(x|x_{i-1})$.\n",
    "- Calculate the acceptance ratio $\\mathcal{A}$, defined below. (Note $\\mathcal{A}$ is always a positive number.)\n",
    "    - If $\\mathcal{A} > 1$, we *always* accept the new point.\n",
    "    - If $\\mathcal{A} < 1$, we *either* accept or reject the new point. We decide to accept or reject randomly: we accept with probability $\\mathcal{A}$ (and therefore we reject with probability $1-\\mathcal{A}$).\n",
    "- The next value in the chain, $x_i$, depends on whether we accept or reject:\n",
    "    - If we accept $x$, we set $x_i = x$, i.e., saving our new sample to the chain.\n",
    "    - If we reject $x$, we set $x_i = x_{i-1}$, i.e., *repeating our previous value in the chain*. \n",
    "    \n",
    "It is easy to forget this last step. Rejection does not mean you try to find a new accepted sample for $x_i$. Rejection means that you *repeat* the previous sample. If you reject ten times in a row, you will be repeating the same values in your chain ten times.\n",
    "\n",
    "For the Metropolis algorithm, the acceptance ratio is\n",
    "$$\\mathcal{A}(x,x^\\prime) = \\frac{P(x)}{P(x^\\prime)}$$\n",
    "where $x$ is the new sample and $x^\\prime$ is the previous sample (i.e., $x_{i-1}$). Thus, if $\\mathcal{A}(x,x^\\prime) > 1$, that means that $x$ is *more probable* than $x^\\prime$. We always keep such points in our sample.\n",
    "\n",
    "On the other hand, we do not *always* reject samples where $\\mathcal{A}(x,x^\\prime) < 1$. \n",
    "For example, let's suppose $\\mathcal{A}(x,x^\\prime) = 0.1$. This means that $x$ is only 10\\% as probable as $x^\\prime$. The procedure described above will accept such samples 10\\% of the time.\n",
    "\n",
    "For the Metropolis-Hastings algorithm, the acceptance ratio is given by a more complicated formula\n",
    "$$\\mathcal{A}(x,x^\\prime) = \\frac{P(x)}{P(x^\\prime)} \\frac{Q(x^\\prime|x)}{Q(x|x^\\prime)} \\, .$$\n",
    "Clearly if $Q(x|x^\\prime) = Q(x^\\prime|x)$, we reduce to the result for the Metropolis algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "p = 0.7\n",
    "num = 10**5\n",
    "\n",
    "# Define P(x)\n",
    "# Note: P[0] = 1-p (tails)\n",
    "#       P[1] = p   (heads)\n",
    "\n",
    "P = [1-p, p]\n",
    "\n",
    "# Initialize the first value in the chain [x0]\n",
    "x_samples = [0]\n",
    "\n",
    "for i in range(num-1):\n",
    "    \n",
    "    # Previous value of x\n",
    "    x_old = x_samples[i]\n",
    "    \n",
    "    # Sample new value of x\n",
    "    x_new = np.random.choice([0,1])\n",
    "    \n",
    "    # Acceptance ratio\n",
    "    A = P[x_new]/P[x_old]\n",
    "    \n",
    "    # Check whether accept or reject\n",
    "    \n",
    "    # Accept always\n",
    "    if A > 1:\n",
    "        x_samples.append(x_new)\n",
    "    \n",
    "    # Accept with probability A\n",
    "    else:\n",
    "        # Randomly decide to accept\n",
    "        r = np.random.rand()\n",
    "        if r < A:\n",
    "            x_samples.append(x_new)\n",
    "        else:\n",
    "            x_samples.append(x_old)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can check that we are getting sensible numbers out. Recall that the true mean and standard deviation of a Bernoulli distribution are $\\mu = p$ and $\\sigma = \\sqrt{p(1-p)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true mean is 0.7\n",
      "Our estimated mean is 0.69983\n",
      "The true standard deviation is 0.45825756949558405\n",
      "Our estimated standard deviation is 0.45833172604566663\n"
     ]
    }
   ],
   "source": [
    "print(\"The true mean is\", p)\n",
    "print(\"Our estimated mean is\", np.mean(x_samples))\n",
    "print(\"The true standard deviation is\", np.sqrt(p*(1-p)))\n",
    "print(\"Our estimated standard deviation is\", np.std(x_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We never explicitly specified the proposal distribution $Q$ in our code ($q$ does not appear anywhere). However, we did this implicitly in `numpy.random.choice` since by default it chooses between the two options with equal probability. This worked since we had chosen $q=0.5$.\n",
    "\n",
    "Notice that although we are sampling heads and tails equally (with `numpy.random.choice`), we are not getting out a mean $\\langle x \\rangle = 0.5$. The acceptance/rejection step is essential here for ensuring that our samples correspond to $P$ even though we are sampling from $Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#46769B>Proof</font>\n",
    "\n",
    "Here we prove that MCMC algorithm really does generate samples for $P$. To be general, we will consider the more general Metropolis-Hastings algorithm. As above, we will consider a Bernoulli distribution to keep things simple. The arguments are similar with more complicated probability distributions, but we will not show them here.\n",
    "\n",
    "Suppose we have a given sample $x_i$. Let's calculate the probability the next sample $x_{i+1}$ is heads or tails according to the Metropolis-Hastings algorithm.\n",
    "\n",
    "First of all, we don't know whether $x_i$ is heads or tails. Let's assign a probability $f$ that $x_i$ is heads and $1-f$ that is tails. That is, if we ran many MCMC simulations, $x_i$ would be heads a fraction $f$ of the time and tails a fraction $1-f$ of the time. \n",
    "\n",
    "Now, there are three ways that $x_{i+1}$ could be heads:\n",
    "- $x_i$ is tails and there is a transition $0 \\to 1$ that is accepted.\n",
    "- $x_i$ is heads and there is a transition $1 \\to 1$. (Such a transition is always accepted since $\\mathcal{A}(1,1) = 1$.)\n",
    "- $x_i$ is heads and there is a transition $1 \\to 0$ that is rejected.\n",
    "\n",
    "The sum of these three probabilities is:\n",
    "$${\\rm Prob}(x_{i+1} = 1) = \\underbrace{(1-f)}_{{\\rm Prob.} \\; x_i = 0} \\times \\underbrace{Q(1|0)}_{{\\rm Prob.} \\; 0\\to 1} \n",
    "\\times \\underbrace{\\mathcal{A}(1,0)}_{{\\rm Prob.\\; accept}} + \n",
    "\\underbrace{f}_{{\\rm Prob.} \\; x_i = 1} \\times \\underbrace{Q(1|1)}_{{\\rm Prob.} \\; 1\\to 1} \n",
    "\\times \\underbrace{\\mathcal{A}(1,1)}_{{\\rm Prob.\\; accept}} + \n",
    "\\underbrace{f}_{{\\rm Prob.} \\; x_i = 1} \\times \\underbrace{Q(0|1)}_{{\\rm Prob.} \\; 1\\to 0} \n",
    "\\times \\underbrace{(1 - \\mathcal{A}(0,1))}_{{\\rm Prob.\\; reject}}$$\n",
    "Now we can plug in our expressions for $Q$ and $\\mathcal{A}$ given above:\n",
    "$${\\rm Prob}(x_{i+1} = 1) = (1-f)\\times q \\times {\\rm min}\\left( \\frac{p}{1-p} \\frac{1-\\bar q}{q}, 1 \\right) \n",
    "+ f \\times \\bar{q} + f \\times (1-\\bar q) \\times \\left(1 - {\\rm min}\\left( \\frac{1-p}{p} \\frac{q}{1-\\bar q}, 1 \\right)\\right) \\, .$$\n",
    "With some algebra we can write this as\n",
    "$${\\rm Prob}(x_{i+1} = 1) = f + \\left[ \\frac{1-f}{1-p} - \\frac{f}{p} \\right] \\times {\\rm min}\\left( p(1-\\bar q), q(1-p) \\right) \\, . \\qquad (1)$$\n",
    "\n",
    "The most interesting solutions to this equation are __stationary__ solutions. This means that the probability of finding heads for sample $x_{i+1}$ is equal to the probability of finding heads for $x_i$.\n",
    "That is, we set the above Eq. (1) equal to $f$:\n",
    "$${\\rm Prob}(x_{i+1} = 1) = f + \\left[ \\frac{1-f}{1-p} - \\frac{f}{p} \\right] \\times {\\rm min}\\left( p(1-\\bar q), q(1-p) \\right) = f \\, .$$\n",
    "The only solution is where the term in brackets is zero,\n",
    "$$\\frac{1-f}{1-p} - \\frac{f}{p}  = 0 \\, ,$$\n",
    "which requires that $f = p$.\n",
    "\n",
    "Let's paraphrase our arguments: \n",
    "- If we run our MCMC algorithm for many iterations, we expect our samples to converge to *some* unique stationary distribution, where the probability of getting heads or tails converges to a fixed value. (There are some technical requirements in order for this to be achieved; further reading can be found [here](https://similarweb.engineering/mcmc/).) \n",
    "- According to the Metropolis-Hastings algorithm (which includes the Metropolis algorithm as a special case), the stationary distribution is where a fraction $p$ of the samples are heads. (This implies obviously, though we did not show it explicitly, that a fraction $1-p$ of the samples are tails.)\n",
    "\n",
    "This is exactly what we wanted: our samples reproduce the target distribution $P(x)$.\n",
    "\n",
    "### <font color=#46769B>Caveat</font>\n",
    "\n",
    "The most important thing to remember about MCMCs is that *only the stationary distribution reproduces the target distribution $P(x)$*.\n",
    "\n",
    "To pick an extreme example, suppose we have a coin that is very biased toward heads, with $p=0.99$. But suppose we start our chain with tails, $x_0 = 0$, and run the Metropolis algorithm with $q = 0.01$. Since $Q(0|0) = 1-q = 99\\%$, we are very likely to sample many tails in a row before getting heads. Obviously, getting 50 or 100 tails in a row is not representative of the target probability distribution $P(x)$ that is strongly biased towards heads!\n",
    "\n",
    "While we are guaranteed to converge to a stationary distribution *eventually* that reproduces $P(x)$, the first samples of our chain many not reproduce $P(x)$ at all. In practice, the following rules apply:\n",
    "- One needs to discard the beginning of the chain, which is known as the __burn-in__ period. The burn-in period is simply the part of your chain where the algorithm is converging to its stationary distribution.\n",
    "- There are good proposal distributions and bad proposal distributions, and there are good initial points $x_0$ and bad ones. Good choices can make the burn-in period small or even zero, while bad choices can prevent your MCMC from burning-in within a reasonable amount of time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
